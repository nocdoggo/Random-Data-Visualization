{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___\n",
    "# Logistic Regression with Python\n",
    "\n",
    "For this lecture we will be working with the [Titanic Data Set from Kaggle](https://www.kaggle.com/c/titanic). This is a very famous data set and very often is a student's first step in machine learning! \n",
    "\n",
    "We'll be trying to predict a classification- survival or deceased.\n",
    "Let's begin our understanding of implementing Logistic Regression in Python for classification.\n",
    "\n",
    "We'll use a \"semi-cleaned\" version of the titanic data set, if you use the data set hosted directly on Kaggle, you may need to do some additional cleaning not shown in this lecture notebook.\n",
    "\n",
    "## Import Libraries\n",
    "Let's import some libraries to get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import os\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "Let's start by reading in the titanic_train.csv file into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_col = ['temp','dewpt','windS','windD','peak','atm','sea','precip']\n",
    "test = [(36.93660287081339, -10, 91, 0), (27.144719506275564, -18.0, 70.0, 0), (11.58672248803828, 0, 40, 0), (208.4802540633975, 23.0, 360.0, 0), (float('nan'), float('nan'), float('nan'), 209), (994.7261493655088, 959.7, 1022.7, 0), (1018.092814298592, 982.1, 1047.8, 0), (0.003582535885167464, 0.0, 0.74, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>No. of invalid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>36.936603</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>91.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewpt</th>\n",
       "      <td>27.144720</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windS</th>\n",
       "      <td>11.586722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windD</th>\n",
       "      <td>208.480254</td>\n",
       "      <td>23.0</td>\n",
       "      <td>360.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peak</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atm</th>\n",
       "      <td>994.726149</td>\n",
       "      <td>959.7</td>\n",
       "      <td>1022.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sea</th>\n",
       "      <td>1018.092814</td>\n",
       "      <td>982.1</td>\n",
       "      <td>1047.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precip</th>\n",
       "      <td>0.003583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean    min      max  No. of invalid\n",
       "temp      36.936603  -10.0    91.00               0\n",
       "dewpt     27.144720  -18.0    70.00               0\n",
       "windS     11.586722    0.0    40.00               0\n",
       "windD    208.480254   23.0   360.00               0\n",
       "peak            NaN    NaN      NaN             209\n",
       "atm      994.726149  959.7  1022.70               0\n",
       "sea     1018.092814  982.1  1047.80               0\n",
       "precip     0.003583    0.0     0.74               0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(test, index = file_col,columns = ['mean','min','max','No. of invalid'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(1991, 1, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = datetime.datetime.strptime('1991-01-01', \"%Y-%m-%d\").date()\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1990-12-31'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(d1 - datetime.timedelta(days=1)).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type in the path of your data folder:C:\\Users\\wayne\\Documents\\coddeC\n"
     ]
    }
   ],
   "source": [
    "#train_1958\n",
    "path = input('Please type in the path of your data folder:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function reads a csv file and process it by \n",
    "# 1. removing the trash\n",
    "# 2. get date into the same format\n",
    "# 3. get time into the same format\n",
    "# 4. fix the wind speed (change into string)\n",
    "# input: filename str ---eg.'2011-2018ord.csv'\n",
    "# output: pandas dataframe\n",
    "def readfile(filename):\n",
    "    \n",
    "    # performing task 1\n",
    "    trash_offset = 25\n",
    "    trash_index = 0\n",
    "    train = pd.read_csv(filename, skiprows= range(0,8), dtype = {'Temp ('+'F)':str, 'Dewpt ('+'F)':str, 'Wind Spd ('+'mph)':str, 'Wind Direction ('+'deg)':str, 'Peak Wind Gust('+'mph)':str, 'Atm Press ('+'hPa)':str, 'Sea Lev Press ('+'hPa)':str, 'Precip ('+'in)':str}  )\n",
    "    train = train.loc[:, ~train.columns.str.contains('^Unnamed')]\n",
    "    nrows = train.shape[0]\n",
    "    #print(nrows)\n",
    "    for x in range(nrows-trash_offset,nrows):\n",
    "        if type(train.loc[x]['Time']) != str:\n",
    "            trash_index = x\n",
    "            break\n",
    "    train.drop(range(trash_index,nrows), inplace = True)\n",
    "   \n",
    "    # performing task 2\n",
    "    # check if the date data is in the right form\n",
    "    date_pattern = re.compile(r'\\d\\d\\d\\d-\\d\\d-\\d\\d')\n",
    "    searchObj = re.search(date_pattern, train['Date'][0])\n",
    "    if not searchObj:\n",
    "        nrows = train.shape[0]\n",
    "        for x in range(0,nrows):\n",
    "            train.at[x,'Date'] = datetime.datetime.strptime(train.at[x,'Date'], \"%m/%d/%Y\").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # performing task 3\n",
    "    # check if time data is in the right form\n",
    "    time_pattern = re.compile(r'^\\d:\\d\\d')\n",
    "    searchObj = re.search(time_pattern, train['Time'][0])\n",
    "    if searchObj:\n",
    "        nrows = train.shape[0]\n",
    "        for x in range(0,nrows):\n",
    "            # task 3\n",
    "            searchObj = re.search(time_pattern, train['Time'][x])\n",
    "            if searchObj:\n",
    "                train.at[x,'Time'] = '0' + train.at[x,'Time']  \n",
    "                \n",
    "    # performing task 4\n",
    "    train = train.astype({train.columns[4]:'str'})\n",
    "    \n",
    "    df_test = train.iloc[0:100]\n",
    "    df_test.to_csv('1.csv',encoding='utf-8',index=False)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes in a date and calculate the mean min max for the features\n",
    "# input: date -- string in the form of 'yyyy-mm-dd' eg:'1958-11-01'\n",
    "#        train -- the main datafram to analyze\n",
    "# output-- list containing:\n",
    "#        mean_result -- datafram for mean of this feature\n",
    "#        min_result -- datafram of min of this feature\n",
    "#        max_result -- datafram of max of this feature\n",
    "#        invalid_feature \n",
    "def analyze_by_day(date, train):\n",
    "    #initialize\n",
    "    mean_result = float('nan')\n",
    "    min_result = float('nan')\n",
    "    max_result = float('nan')\n",
    "    invalid_feature = 0\n",
    "    #readin feature data\n",
    "    train_found = train[train['Date'] == date]\n",
    "    \n",
    "    #print(train_found)\n",
    "    \n",
    "    #train_found.shape[0]\n",
    "    # calculate how many 'm' there are for each feature out of 24 days\n",
    "    m_count = 0\n",
    "    for x in range(0, train_found.shape[0]):\n",
    "            # count the number of 'm'\n",
    "        if train_found.iloc[x,2].lower() == 'm':\n",
    "            m_count += 1\n",
    "    # if there are total of 6 or more 'm' make this feature invalid\n",
    "    if m_count >= 6:\n",
    "        invalid_feature = 1\n",
    "        \n",
    "    #print(invalid_feature) \n",
    "    if invalid_feature != 1:\n",
    "        # now we caculate the info from this legit feature\n",
    "        df2 = train_found.drop(columns =['Date','Time'])\n",
    "        df1 = df2.apply(pd.to_numeric, errors='coerce')\n",
    "        df1.fillna(value=df1.mean(), inplace = True)\n",
    "\n",
    "        mean_result = df1.mean()\n",
    "        min_result = df1.min()\n",
    "        max_result = df1.max()\n",
    "    \n",
    "    #now we got evertthing return the calculated value\n",
    "    #print(invalid_feature)\n",
    "    #print(mean_result)\n",
    "\n",
    "        \n",
    "    return mean_result,min_result,max_result,invalid_feature\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_by_feature(feature):\n",
    "    print(feature)\n",
    "    mean_temp = []\n",
    "    min_temp =[]\n",
    "    max_temp = []\n",
    "    invalid_temp = []\n",
    "    train_feature = pd.read_csv(feature+'.csv', dtype = str)\n",
    "    #print(train_feature['Date'])\n",
    "    \n",
    "    train_index = pd.unique(train_feature['Date'])\n",
    "    train_index = list(train_index)\n",
    "    #print(train_index)\n",
    "    for i in range(len(train_index)):\n",
    "        temp = analyze_by_day(train_index[i], train_feature)\n",
    "        \n",
    "        mean_temp.append(temp[0])\n",
    "        min_temp.append(temp[1])\n",
    "        max_temp.append(temp[2])\n",
    "        invalid_temp.append(temp[3])\n",
    "\n",
    "    # group them together\n",
    "    mean_df = pd.DataFrame(mean_temp)\n",
    "    min_df = pd.DataFrame(min_temp)\n",
    "    max_df = pd.DataFrame(max_temp)\n",
    "    invalid_df = pd.DataFrame(invalid_temp)\n",
    "\n",
    "    # calculate mean and other stuff\n",
    "    mean_df.fillna(value=mean_df.mean(), inplace = True)\n",
    "    min_df.fillna(value=min_df.mean(), inplace = True)\n",
    "    max_df.fillna(value=mean_df.mean(), inplace = True)\n",
    "    \n",
    "    mean_final = mean_df.mean()\n",
    "    min_final = min_df.min()\n",
    "    max_final = max_df.max()\n",
    "    invalid_final = invalid_df.sum()\n",
    "    return mean_final[0],min_final[0],max_final[0],invalid_final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the location of data you want to select (ugn or ord):ord\n",
      "1958-1970ord.csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'readfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-9c7006670898>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msearchObj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlistOfFiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mtrain_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_temp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreadfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlistOfFiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'readfile' is not defined"
     ]
    }
   ],
   "source": [
    "# read all the csv files \n",
    "file_selection = ''\n",
    "while 1==1:\n",
    "    file_selection = input('Please input the location of data you want to select '+ '(ugn or ord'+'):')\n",
    "    if file_selection == 'ugn' or file_selection == 'ord':\n",
    "        break\n",
    "listOfFiles = os.listdir(path)\n",
    "\n",
    "file_pattern_ord = re.compile(r'\\d\\d\\d\\dord.csv')\n",
    "file_pattern_ugn = re.compile(r'\\d\\d\\d\\dugn.csv')\n",
    "if file_selection == 'ugn':\n",
    "    file_pattern = file_pattern_ugn\n",
    "else:\n",
    "    file_pattern = file_pattern_ord\n",
    "train_temp = pd.DataFrame()\n",
    "for x in range(0,len(listOfFiles)):\n",
    "    searchObj = re.search(file_pattern, listOfFiles[x])\n",
    "    if searchObj:\n",
    "        print (listOfFiles[x] )\n",
    "        train_temp = pd.concat([train_temp,readfile(path+'/'+listOfFiles[x])], axis = 0, ignore_index=True)\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into 8 different files \n",
    "file_col = ['temp','dewpt','windS','windD','peak','atm','sea','precip']\n",
    "train_1 = train_temp.iloc[:,[0,1,2]].head(5000)\n",
    "train_1.to_csv(file_col[0]+'.csv',encoding = 'utf-8',index = False)\n",
    "train_2 = train_temp.iloc[:,[0,1,3]].head(5000)\n",
    "train_2.to_csv(file_col[1]+'.csv',encoding = 'utf-8',index = False)\n",
    "train_3 = train_temp.iloc[:,[0,1,4]].head(5000)\n",
    "train_3.to_csv(file_col[2]+'.csv',encoding = 'utf-8',index = False)\n",
    "train_4 = train_temp.iloc[:,[0,1,5]].head(5000)\n",
    "train_4.to_csv(file_col[3]+'.csv',encoding = 'utf-8',index = False)\n",
    "train_5 = train_temp.iloc[:,[0,1,6]].head(5000)\n",
    "train_5.to_csv(file_col[4]+'.csv',encoding = 'utf-8',index = False)\n",
    "train_6 = train_temp.iloc[:,[0,1,7]].head(5000)\n",
    "train_6.to_csv(file_col[5]+'.csv',encoding = 'utf-8',index = False)\n",
    "train_7 = train_temp.iloc[:,[0,1,8]].head(5000)\n",
    "train_7.to_csv(file_col[6]+'.csv',encoding = 'utf-8',index = False)\n",
    "train_8 = train_temp.iloc[:,[0,1,9]].head(5000)\n",
    "train_8.to_csv(file_col[7]+'.csv',encoding = 'utf-8',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(2)\n",
    "result = pool.map(analyze_by_feature, file_col)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check ord time span\n",
    "while file_selection == 'ord':\n",
    "    first_date = input(\"From 1958-11-01 to 2018-12-30, please input a valid starting date as in yyyy-mm-dd: \")\n",
    "    d1 = datetime.datetime.strptime(first_date, \"%Y-%m-%d\").date()\n",
    "    if d1 >=datetime.date(1958,11,1) and d1 <=datetime.date(2018,12,30):\n",
    "        break\n",
    "\n",
    "while file_selection == 'ord':\n",
    "    second_date = input(\"From 1958-11-02 to 2018-12-31, please input the ending date as in yyyy-mm-dd: \")\n",
    "    d2 = datetime.datetime.strptime(second_date, \"%Y-%m-%d\").date()\n",
    "    if d2 >=datetime.date(1958,11,2) and d2 <=datetime.date(2018,12,31):\n",
    "        break\n",
    "        \n",
    "# check ugn time span        \n",
    "while file_selection == 'ugn':\n",
    "    first_date = input(\"From 1989-04-21 to 2018-12-30, please input a valid starting date as in yyyy-mm-dd: \")\n",
    "    d1 = datetime.datetime.strptime(first_date, \"%Y-%m-%d\").date()\n",
    "    if d1 >=datetime.date(1989,4,21) and d1 <=datetime.date(2018,12,30):\n",
    "        break\n",
    "        \n",
    "while file_selection == 'ugn':        \n",
    "    second_date = input(\"From 1989-04-22 to 2018-12-31, please input the ending date as in yyyy-mm-dd: \")\n",
    "    d2 = datetime.datetime.strptime(second_date, \"%Y-%m-%d\").date()\n",
    "    if d2 >=datetime.date(1989,4,22) and d2 <=datetime.date(2018,12,31):\n",
    "        break    \n",
    "\n",
    "delta = d2-d1\n",
    "\n",
    "while delta.days <= 0:\n",
    "    print('Your starting date is later than your ending date, try again please')\n",
    "    first_date = input(\"Please input a valid starting date as in yyyy-mm-dd: \")\n",
    "    d1 = datetime.datetime.strptime(first_date, \"%Y-%m-%d\").date()\n",
    "    second_date = input(\"Please input a valid ending date as in yyyy-mm-dd: \")\n",
    "    d2 = datetime.datetime.strptime(second_date, \"%Y-%m-%d\").date()\n",
    "    delta = d2-d1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "mean_temp = []\n",
    "min_temp =[]\n",
    "max_temp = []\n",
    "invalid_temp = []\n",
    "\n",
    "if delta.days >0:\n",
    "    for i in range(delta.days+1):\n",
    "        temp_day = d1+datetime.timedelta(days=i)\n",
    "        day_str = temp_day.strftime('%Y-%m-%d')\n",
    "        temp = analyze_by_day(day_str, train_temp)\n",
    "        \n",
    "        mean_temp.append(temp[0])\n",
    "        min_temp.append(temp[1])\n",
    "        max_temp.append(temp[2])\n",
    "        invalid_temp.append(temp[3])\n",
    "# group them together\n",
    "mean_df = pd.DataFrame(mean_temp)\n",
    "min_df = pd.DataFrame(min_temp)\n",
    "max_df = pd.DataFrame(max_temp)\n",
    "invalid_df = pd.DataFrame(invalid_temp)\n",
    "\n",
    "# calculate mean and other stuff\n",
    "for x in range(0,8):\n",
    "    mean_df[mean_df.columns[x]].fillna(value=mean_df[mean_df.columns[x]].mean(), inplace = True)\n",
    "    min_df[min_df.columns[x]].fillna(value=min_df[min_df.columns[x]].mean(), inplace = True)\n",
    "    max_df[max_df.columns[x]].fillna(value=mean_df[max_df.columns[x]].mean(), inplace = True)\n",
    "    \n",
    "mean_final = mean_df.mean()\n",
    "min_final = min_df.min()\n",
    "max_final = max_df.max()\n",
    "\n",
    "print('The mean of the range is:')\n",
    "print(mean_final)\n",
    "print('\\nThe min of the range is:')\n",
    "print(min_final)\n",
    "print('\\nThe max of the range is:')\n",
    "print(max_final)\n",
    "\n",
    "cols = ['Temp', 'Dewpt', 'Wind Spd', 'Wind Direction', 'Peak Wind Gust', 'Atm Press', 'Sea Lev Press', 'Precip']\n",
    "print('the number of invalid values in each features is:\\n')\n",
    "for i in range(0,8):\n",
    "    print(cols[i]+':'+' ')\n",
    "    print(invalid_df.sum()[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# now that we have read all the files ask user to input a range\n",
    "first_date = '1991-01-01'\n",
    "d1 = datetime.datetime.strptime(first_date, \"%Y-%m-%d\").date()\n",
    "#print(d1)\n",
    "second_date = '2000-01-01'\n",
    "d2 = datetime.datetime.strptime(second_date, \"%Y-%m-%d\").date()\n",
    "delta = d2-d1\n",
    "\n",
    "print(delta.days)\n",
    "\n",
    "mean_temp = []\n",
    "min_temp =[]\n",
    "max_temp = []\n",
    "invalid_temp = []\n",
    "if delta.days >0:\n",
    "    for i in range(delta.days+1):\n",
    "        temp_day = d1+datetime.timedelta(days=i)\n",
    "        day_str = temp_day.strftime('%Y-%m-%d')\n",
    "        temp = analyze_by_day(day_str, train_temp)\n",
    "        \n",
    "        mean_temp.append(temp[0])\n",
    "        min_temp.append(temp[1])\n",
    "        max_temp.append(temp[2])\n",
    "        invalid_temp.append(temp[3])\n",
    "        print('this is the: ')\n",
    "        print(i)\n",
    "        print('\\n')\n",
    "        print('mean')\n",
    "        print(temp[0])\n",
    "        print('min')\n",
    "        print(temp[1])\n",
    "        print('max')\n",
    "        print(temp[2])\n",
    "        print('inv')\n",
    "        print(temp[3])\n",
    "        print('\\n')\n",
    "# group them together\n",
    "\n",
    "mean_df = pd.DataFrame(mean_temp)\n",
    "min_df = pd.DataFrame(min_temp)\n",
    "max_df = pd.DataFrame(max_temp)\n",
    "invalid_df = pd.DataFrame(invalid_temp)\n",
    "\n",
    "# calculate mean and other stuff\n",
    "for x in range(0,8):\n",
    "    mean_df[mean_df.columns[x]].fillna(value=mean_df[mean_df.columns[x]].mean(), inplace = True)\n",
    "    min_df[min_df.columns[x]].fillna(value=min_df[min_df.columns[x]].mean(), inplace = True)\n",
    "    max_df[max_df.columns[x]].fillna(value=mean_df[max_df.columns[x]].mean(), inplace = True)\n",
    "    \n",
    "mean_final = mean_df.mean()\n",
    "min_final = min_df.min()\n",
    "max_final = max_df.max()\n",
    "\n",
    "print('The mean of the range is:')\n",
    "print(mean_final)\n",
    "print('\\nThe min of the range is:')\n",
    "print(min_final)\n",
    "print('\\nThe max of the range is:')\n",
    "print(max_final)\n",
    "\n",
    "cols = ['Temp', 'Dewpt', 'Wind Spd', 'Wind Direction', 'Peak Wind Gust', 'Atm Press', 'Sea Lev Press', 'Precip']\n",
    "print('the number of invalid values in each features is:\\n')\n",
    "for i in range(0,8):\n",
    "    print(cols[i]+':'+' ')\n",
    "    print(invalid_df.sum()[i])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# calculate mean and other stuff\n",
    "for x in range(0,8):\n",
    "    mean_df[mean_df.columns[x]].fillna(value=mean_df[mean_df.columns[x]].mean(), inplace = True)\n",
    "    min_df[min_df.columns[x]].fillna(value=min_df[min_df.columns[x]].mean(), inplace = True)\n",
    "    max_df[max_df.columns[x]].fillna(value=mean_df[max_df.columns[x]].mean(), inplace = True)\n",
    "    \n",
    "mean_final = mean_df.mean()\n",
    "min_final = min_df.min()\n",
    "max_final = max_df.max()\n",
    "\n",
    "print('The mean of the range is:')\n",
    "print(mean_final)\n",
    "print('\\nThe min of the range is:')\n",
    "print(min_final)\n",
    "print('\\nThe max of the range is:')\n",
    "print(max_final)\n",
    "\n",
    "cols = ['Temp', 'Dewpt', 'Wind Spd', 'Wind Direction', 'Peak Wind Gust', 'Atm Press', 'Sea Lev Press', 'Precip']\n",
    "print('the number of invalid values in each features is:\\n')\n",
    "for i in range(0,8):\n",
    "    print(cols[i]+':'+' ')\n",
    "    print(invalid_df.sum()[i])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# stores the output data\n",
    "invalid_series = invalid_df.sum()\n",
    "invalid_series.index = (list(mean_final.index))\n",
    "df_output = pd.concat([mean_final, min_final, max_final, invalid_series], axis = 1)\n",
    "df_output.columns = ['mean', 'min', 'max', 'No. of invalid']\n",
    "df_output.to_csv('data_output_test.csv',encoding='utf-8')\n",
    "df_output\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# parallel the task\n",
    "idx_from = train_temp.index[train_temp['Date'] == '1990-01-03'][0]\n",
    "print(idx_from)\n",
    "idx_to = train_temp.index[train_temp['Date'] == '1991-01-04'][0]\n",
    "#print(idx_to)\n",
    "#print(train_temp.iloc[idx_from-1])\n",
    "train_todo = train_temp.iloc[range(idx_from, idx_to)]\n",
    "#print(type(train_todo))\n",
    "train_index = pd.unique(train_todo['Date'])\n",
    "train_index = list(train_index)\n",
    "print((train_index))\n",
    "\n",
    "#pool = multiprocessing.Pool()\n",
    "#result = pool.map(analyze_by_day, train_index)\n",
    "#pool.\n",
    "#result = map(lambda p: analyze_by_day(p, train_todo), train_index)\n",
    "#for x in result:\n",
    "   # print(x)\n",
    "#print((result))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
